{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3bb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place this as the FIRST cell, before importing torch.\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# Seed Python, NumPy, Torch (CPU and CUDA)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Helpers for DataLoader reproducibility\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from src.datasets.seeg_dataset import SEEGDataset\n",
    "from src.models.model import SEEGFusionModel, BaselineModel\n",
    "from src.training.train import train_model\n",
    "from src.training.evaluate import evaluate_model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(train_ds):\n",
    "    labels = np.array([v[1] for v in train_ds])\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(labels == t)[0]) for t in np.unique(labels)])\n",
    "    weight = class_sample_count.sum() / class_sample_count\n",
    "    return torch.from_numpy(weight).float()\n",
    "\n",
    "# Helper to get indices for specific subjects\n",
    "def get_subject_indices(dataset, subj_list):\n",
    "    return [i for i, s in enumerate(dataset.data) if s['subject'] in subj_list]\n",
    "\n",
    "# Create dataset once (loads all subjects)\n",
    "subjects=['Epat31','Epat35','Epat37','Epat38','Spat31','Spat37']\n",
    "full_dataset = SEEGDataset(subjects=subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745817d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: LOPO outer loop\n",
    "model_type = 'Fusion'\n",
    "metric_dict = {}\n",
    "for test_subj in subjects:\n",
    "    logger.info(f\"\\n=== Test subject: {test_subj} ===\")\n",
    "    remaining_subjs = [s for s in subjects if s != test_subj]\n",
    "\n",
    "    # Outer split: test vs remaining\n",
    "    test_idx = get_subject_indices(full_dataset, [test_subj])\n",
    "    test_ds = Subset(full_dataset, test_idx)\n",
    "\n",
    "    # Inner split subjects (for hyperparam tuning)\n",
    "    # Shuffle remaining subjects so different folds vary\n",
    "    random.shuffle(remaining_subjs)\n",
    "\n",
    "    # Do 5 different inner splits (4 train / 1 val)\n",
    "    inner_splits = []\n",
    "    for i in range(5):\n",
    "        # rotate subjects for different validation sets\n",
    "        val_subjs = remaining_subjs[i]\n",
    "        train_subjs = [s for s in remaining_subjs if s not in val_subjs]\n",
    "        inner_splits.append((train_subjs, val_subjs))\n",
    "\n",
    "    # Run inner CV for this test subject\n",
    "    for k, (train_subjs, val_subjs) in enumerate([inner_splits[0]]):\n",
    "        logger.info(f\"\\nInner split {k+1}: train={train_subjs}, val={val_subjs}\")\n",
    "\n",
    "        train_idx = get_subject_indices(full_dataset, train_subjs)\n",
    "        val_idx = get_subject_indices(full_dataset, val_subjs)\n",
    "\n",
    "        train_ds = Subset(full_dataset, train_idx)\n",
    "        val_ds = Subset(full_dataset, val_idx)\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=0, worker_init_fn=seed_worker, generator=g),\n",
    "            'val': DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=0, worker_init_fn=seed_worker, generator=g),\n",
    "            'test': DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=0, worker_init_fn=seed_worker, generator=g)\n",
    "        }\n",
    "\n",
    "        weights = compute_class_weights(train_ds)\n",
    "\n",
    "        if model_type == 'Fusion':\n",
    "            model = SEEGFusionModel(embed_dim=128, n_classes=2, device=device)\n",
    "        elif model_type == 'Baseline':\n",
    "            model = BaselineModel(embed_dim=128, n_classes=2, device=device, stim_model='convergent', n_elecs=25, generator=g)\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(\n",
    "            optimizer,\n",
    "            base_lr=1e-6,\n",
    "            max_lr=1e-4,\n",
    "            step_size_up=50,\n",
    "            step_size_down=50,\n",
    "            cycle_momentum=False\n",
    "        )\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "\n",
    "        model, history, best_epoch = train_model(\n",
    "            model=model,\n",
    "            dataloaders=dataloaders,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            save_prefix=f'{test_subj}_model_{model_type}_split_{k}',\n",
    "            n_epochs=10,\n",
    "            patience=2,\n",
    "        )\n",
    "\n",
    "    metrics = evaluate_model(model, dataloaders['test'], device)\n",
    "    metric_dict[test_subj] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f3c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_final_dict(metric_dict):\n",
    "\n",
    "  final_dict = {}\n",
    "\n",
    "  for d in metric_dict.values():\n",
    "    for k,v in d.items():\n",
    "      final_dict.setdefault(k,[]).append(v)\n",
    "\n",
    "  for k in final_dict:\n",
    "    vals = np.array(final_dict[k])\n",
    "    print(f'{k}:           {np.mean(vals):0.3f} +/- {np.std(vals):0.3f}')\n",
    "  \n",
    "  return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_final_dict = convert_to_final_dict(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2375728",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metric_dict = {}\n",
    "experiments_dir = Path('../experiments')\n",
    "for model_path in list(experiments_dir.glob('*model_Baseline_split_0_best_*.pt')):\n",
    "  model = BaselineModel(embed_dim=128, n_classes=2, device=device, stim_model='convergent', n_elecs=25, generator=g)\n",
    "  model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "  model.to(device)\n",
    "  test_subj = model_path.name.split('_')[0]\n",
    "\n",
    "  test_idx = get_subject_indices(full_dataset, [test_subj])\n",
    "  test_ds = Subset(full_dataset, test_idx)\n",
    "\n",
    "  dataloader = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=0, worker_init_fn=seed_worker, generator=g)\n",
    "  metrics = evaluate_model(model, dataloader, device)\n",
    "  baseline_metric_dict[test_subj] = metrics\n",
    "\n",
    "baseline_final_dict = convert_to_final_dict(baseline_metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a72a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "for val in ['auroc', 'f1', 'youden_index']:\n",
    "    pval = wilcoxon(baseline_final_dict[val], fusion_final_dict[val]).pvalue\n",
    "    print(f\"{val}, p-value={pval}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
